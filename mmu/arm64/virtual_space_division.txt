in arch/arm64/include/asm/memory.h :

#define VA_BITS			(CONFIG_ARM64_VA_BITS)


1. How to define ARM64_VA_BITS

in arch/arm64/Kconfig :

ARM64_VA_BITS_36	depends on 	16K_PAGES
ARM64_VA_BITS_39	depends on 	4K_PAGES
ARM64_VA_BITS_42	depends on 	64K_PAGES
ARM64_VA_BITS_47	depends on 	16K_PAGES
ARM64_VA_BITS_48			ALL


2. The conversion between fix address ID and virtual address

in include/asm-generic/fixmap.h :

#define __fix_to_virt(x)	(FIXADDR_TOP - ((x) << PAGE_SHIFT))
#define __virt_to_fix(x)	((FIXADDR_TOP - ((x)&PAGE_MASK)) >> PAGE_SHIFT)

3. The definition of FIXADDR_TOP

It is architecture-dependent.

For ARM64, it is :
#define FIXADDR_TOP		(PCI_IO_START - SZ_2M)

4. The virtual space definitions

#define VA_START		(UL(0xffffffffffffffff) << VA_BITS)
#define PAGE_OFFSET		(UL(0xffffffffffffffff) << (VA_BITS - 1))
#define KIMAGE_VADDR		(MODULES_END)
#define MODULES_END		(MODULES_VADDR + MODULES_VSIZE)
#define MODULES_VADDR		(VA_START + KASAN_SHADOW_SIZE)
#define MODULES_VSIZE		(SZ_128M)
#define VMEMMAP_START		(PAGE_OFFSET - VMEMMAP_SIZE)
#define PCI_IO_END		(VMEMMAP_START - SZ_2M)
#define PCI_IO_START		(PCI_IO_END - PCI_IO_SIZE)
#define FIXADDR_TOP		(PCI_IO_START - SZ_2M)
#define TASK_SIZE_64		(UL(1) << VA_BITS)

	-------------------------  -1UL (highest VA)
	|			|
	|			| 	(1 << (VA_BITS - 1))
	|			|
	-------------------------  PAGE_OFFSET
	|	VMEMMAP		| 	VMEMMAP_SIZE
	-------------------------  VMEMMAP_START
	|	SZ_2M		|	space gap
	-------------------------  PCI_IO_END
	|	PCI_IO		|	PCI_IO_SIZE
	-------------------------  PCI_IO_START
	|	SZ_2M		|	space gap
	-------------------------  FIXADDR_TOP
	|			|
	|	KIMAGE		|
	-------------------------  KIMAGE_VADDR/MODULES_END
	|	MODULES		|
	|			|	MODULES_VSIZE
	-------------------------  MODULES_VADDR
	|			|
	|	KASAN_SHADOW	|	KASAN_SHADOW_SIZE (1UL << (VA_BITS - 3))
	|			|
	-------------------------  VA_START
	|			|
	|			|
	|	BIG GAP		|
	|			|
	-------------------------  TASK_SIZE_64 (UL(1) << VA_BITS)
	|			|
	|			|
	|	User space	|	
	|			|
	------------------------- 0




For ARM,
in arch/arm/include/asm/memory.h :

#define PAGE_OFFSET		UL(CONFIG_PAGE_OFFSET)

#define TASK_SIZE		(UL(CONFIG_PAGE_OFFSET) - UL(SZ_16M))
#define TASK_UNMAPPED_BASE	ALIGN(TASK_SIZE / 3, SZ_16M)

And CONFIG_PAGE_OFFSET is :

config PAGE_OFFSET
        hex
        default PHYS_OFFSET if !MMU
        default 0x40000000 if VMSPLIT_1G
        default 0x80000000 if VMSPLIT_2G
        default 0xB0000000 if VMSPLIT_3G_OPT
        default 0xC0000000

So, For ARM, the user space is ajacent to kernel space.


the layout maybe like this( I haven't checked the code, just copy from
some web) :


VMALLOC_END        feffffff        Free for platform use, recommended.
                                VMALLOC_END must be aligned to a 2MB
                                boundary.

VMALLOC_START        VMALLOC_END-1        vmalloc() / ioremap() space.
                                Memory returned by vmalloc/ioremap will
                                be dynamically placed in this region.
                                VMALLOC_START may be based upon the value
                                of the high_memory variable.

PAGE_OFFSET        high_memory-1        Kernel direct-mapped RAM region.
                                This maps the platforms RAM, and typically
                                maps all platform RAM in a 1:1 relationship.

TASK_SIZE        PAGE_OFFSET-1        Kernel module space
                                Kernel modules inserted via insmod are
                                placed here using dynamic mappings.

00001000        TASK_SIZE-1        User space mappings
                                Per-thread mappings are placed here via
                                the mmap() system call.

00000000        00000fff        CPU vector page / null pointer trap
                                CPUs which do not support vector remapping
                                place their vector page here.  NULL pointer
                                dereferences by both the kernel and user
                                space are also caught via this mapping.

================ How to map the RAM memory===========


1. There are two regions of RAM according to the usage;

one is for kernel Image;
Another is for kernel available memory;


---For Kernel Image space(also populate some memory region, but the virtual
---space is different from t he kernel linear region.

VA -----> PA :

#define __pa_symbol(x)	__phys_addr_symbol(RELOC_HIDE((unsignedlong)(x), 0))

This macro will return the PA of a symbol in kernel Image;
The VA should be in [KERNEL_START, KERNEL_END);

#define __kimg_to_phys(addr)	((addr) - kimage_voffset)

#define __pa_symbol_nodebug(x)	__kimg_to_phys((phys_addr_t)(x))

#define __phys_to_kimg(x)	((unsigned long)((x) + kimage_voffset))

----------------



in head.S :

	ldr_l	x4, kimage_vaddr		// Save the offset between
	sub	x4, x4, x0			// the kernel virtual and
	str_l	x4, kimage_voffset, x5		// physical mappings

Here, x0 is __PHYS_OFFSET; (VA)

after ldr_l x4, kimage_vaddr, the physical address corresponds to kimage_vaddr
was saved in x4; Then the PA - VA (base) will be stored in kimage_voffset;


The VA of kimage_vaddr is _text - TEXT_OFFSET;

THE __PHYS_OFFSET is defined :
#define __PHYS_OFFSET	(KERNEL_START - TEXT_OFFSET)

And before calling __primary_switched, x0 is set as that:

	adrp	x0, __PHYS_OFFSET
So, 'sub x4, x4, x0' will have the result of _text (VA) - PA(KERNEL_START)

So, the value in kimage_voffset is the offset between the KERNEL_START and
start physical address of kernel;

-------The kernel linear region( The corresponding virtual space from
PAGE_OFFSET) -------

======== PA -----> VA =======
/* The start physical memory address */
#define PHYS_OFFSET	({ VM_BUG_ON(memstart_addr & 1); memstart_addr;})

#define __phys_to_virt(x) ((unsigned long)((x) - PHYS_OFFSET) | PAGE_OFFSET)

So, __phys_to_virt(x) can convert the physical to virtual for non-kernel memory;

PHYS_OFFSET is corresponding to PAGE_OFFSET in this mapping for non-kernel
memory;

======= VA -----> PA ========
#define __is_lm_address(addr)	(!!((addr) & BIT(VA_BITS - 1)))

#define __lm_to_phys(addr)	(((addr) & ~PAGE_OFFSET) + PHYS_OFFSET)


======= An unified VA ----> PA macro ===========
As there are distinct separator between kernel image virtual and linear
virtual, an unified macro for VA to PA is :

#define __virt_to_phys_nodebug(x) ({					\
	phys_addr_t __x = (phys_addr_t)(x);				\
	__is_lm_address(__x) ? __lm_to_phys(__x) :			\
			       __kimg_to_phys(__x);			\
})


