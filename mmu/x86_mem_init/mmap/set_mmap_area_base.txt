
As mmap() will setup the mapping between userland space and kernel space, we
firstly should know what is the userlan space range/area, then mmap() can
allocate idle userland space region for this mapping.

unsigned long
get_unmapped_area(struct file *file, unsigned long addr, unsigned long len,
		unsigned long pgoff, unsigned long flags)
{
	...
	get_area = current->mm->get_unmapped_area;
	...
}

1. Where was the 'current->mm->get_unmapped_area' initialized?

Please note, this 'get_unmapped_area()' is thread-specific;

void setup_new_exec(struct linux_binprm * bprm)
{
	arch_pick_mmap_layout(current->mm);


So, it is obvious that setup_new_exec() for a new thread will call
arch_pick_mmap_layout(current->mm) to setup these :

	mm->get_unmapped_area;
	mm->mmap_legacy_base or mm->mmap_base;

if mmap_is_legacy() returns TRUE, mm->mmap_legacy_base will be applied;


static int mmap_is_legacy(void)
{
	if (current->personality & ADDR_COMPAT_LAYOUT)
		return 1;

	if (rlimit(RLIMIT_STACK) == RLIM_INFINITY)
		return 1;

	return sysctl_legacy_va_layout;
}

For x86, there are these definitions:

arch/x86/include/asm/processor.h :

#ifdef HAVE_ARCH_PICK_MMAP_LAYOUT
int sysctl_legacy_va_layout;
#endif

So, normally, '/proc/sys/vm/legacy_va_layout' will be used to set the mmap mode;
It seems that the default value is ZERO.

2. How to define the userland mmap area?

void arch_pick_mmap_layout(struct mm_struct *mm)
{
	if (mmap_is_legacy())
		mm->get_unmapped_area = arch_get_unmapped_area;
	else
		mm->get_unmapped_area = arch_get_unmapped_area_topdown;

	arch_pick_mmap_base(&mm->mmap_base, &mm->mmap_legacy_base,
			arch_rnd(mmap64_rnd_bits), tasksize_64bit());



2.1 arch_rnd(mmap64_rnd_bits)

in arch/x86/mm/mmap.c :
# define mmap32_rnd_bits  mmap_rnd_bits
# define mmap64_rnd_bits  mmap_rnd_bits

fdef CONFIG_HAVE_ARCH_MMAP_RND_BITS
const int mmap_rnd_bits_min = CONFIG_ARCH_MMAP_RND_BITS_MIN;
const int mmap_rnd_bits_max = CONFIG_ARCH_MMAP_RND_BITS_MAX;
int mmap_rnd_bits __read_mostly = CONFIG_ARCH_MMAP_RND_BITS;
#endif

On x86, the 'CONFIG_HAVE_ARCH_MMAP_RND_BITS' is assigned like that:
arch/x86/Kconfig:106:	select HAVE_ARCH_MMAP_RND_BITS		if MMU

arch/Kconfig:
config ARCH_MMAP_RND_BITS_DEFAULT
        int

config ARCH_MMAP_RND_BITS
        int "Number of bits to use for ASLR of mmap base address" if EXPERT
        range ARCH_MMAP_RND_BITS_MIN ARCH_MMAP_RND_BITS_MAX
        default ARCH_MMAP_RND_BITS_DEFAULT if ARCH_MMAP_RND_BITS_DEFAULT
        default ARCH_MMAP_RND_BITS_MIN
        depends on HAVE_ARCH_MMAP_RND_BITS

So, ARCH_MMAP_RND_BITS is decided by ARCH_MMAP_RND_BITS_MIN.

in arch/x86/Kconfig:203:config ARCH_MMAP_RND_BITS_MIN :
config ARCH_MMAP_RND_BITS_MIN
        default 28 if 64BIT
        default 8

So, For X86_64, the random page number will use the 28 LSB of the random value
generated by get_randon_long():

static unsigned long arch_rnd(unsigned int rndbits)
{
	return (get_random_long() & ((1UL << rndbits) - 1)) << PAGE_SHIFT;
}

The range value is in the range [0, 2 << (28 + PAGE_SHIFT)] for X86_64. The
maximum is 1T; This is acceptable as there are total (2 << 47) userland space.

On X86_32, the default mmap_rnd_bits is 8, so the random range is [0, 2 << 20].
For about 3G userland space, it is ok.


What is the exact mmap base for legacy mmap?

static unsigned long mmap_legacy_base(unsigned long rnd,
				      unsigned long task_size)
{
	return __TASK_UNMAPPED_BASE(task_size) + rnd;
}

#define __TASK_UNMAPPED_BASE(task_size)	(PAGE_ALIGN(task_size / 3))

So, for legacy mmap, the mmap base is the (1/3 of TASK_SIZE_MAX + random base);



2.2 topdown mmap area

mm->get_unmapped_area = arch_get_unmapped_area_topdown;

static void arch_pick_mmap_base(unsigned long *base, unsigned long *legacy_base,
		unsigned long random_factor, unsigned long task_size)
{
	*legacy_base = mmap_legacy_base(random_factor, task_size);
	if (mmap_is_legacy())
		*base = *legacy_base;
	else
		*base = mmap_base(random_factor, task_size);
}

void arch_pick_mmap_layout(struct mm_struct *mm)
{
	...
		mm->get_unmapped_area = arch_get_unmapped_area_topdown;

	arch_pick_mmap_base(&mm->mmap_base, &mm->mmap_legacy_base,
			arch_rnd(mmap64_rnd_bits), tasksize_64bit());
	...
}

For topdown mmap, the mm->mmap_base is 'mmap_base(random_factor, task_size)'.
Here, random_factor is 'arch_rnd(mmap64_rnd_bits)'.


static unsigned long mmap_base(unsigned long rnd, unsigned long task_size)
{
	unsigned long gap = rlimit(RLIMIT_STACK);
	unsigned long gap_min, gap_max;

	/*
	 * Top of mmap area (just below the process stack).
	 * Leave an at least ~128 MB hole with possible stack randomization.
	 */
	gap_min = SIZE_128M + stack_maxrandom_size(task_size);
	gap_max = (task_size / 6) * 5;

	if (gap < gap_min)
		gap = gap_min;
	else if (gap > gap_max)
		gap = gap_max;

	return PAGE_ALIGN(task_size - gap - rnd);
}

** This mmap_base() will clob the gap in the range of [gap_min, gap_max]. If the
gap = rlimit(RLIMIT_STACK) is in that range, than will apply that gap to
seperate the stack and the mmap area. Otherwise, just adjust the gap with the
gap_min or gap_max. gap_min/gap_max is the minimum/maximum size of the summary
of stack and the gap between stack and the mmap area.

** The rlimit(RLIMIT_STACK) should be set by SYSCALL_DEFINE2(setrlimit,... which
defined in kernel/sys.c;
** The input 'rnd' of mmap_base() is the random gap size;





